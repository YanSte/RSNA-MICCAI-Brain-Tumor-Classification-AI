{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/yannicksteph/rsna-miccai-brain-tumor-classification?scriptVersionId=130446446\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<a href=\"https://www.kaggle.com/code/yannicksteph/rsna-miccai-brain-tumor-classification\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{"_uuid":"216dfa24-cff8-4943-86cf-879051270756","_cell_guid":"214490b4-8f69-44ac-8f2d-792f23fda98e","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true}},{"cell_type":"markdown","source":"# Work in progress 🚧","metadata":{"_uuid":"09fd31b7-1887-4aca-9ad4-abb1b11fd035","_cell_guid":"4bbb47e1-9ced-4aae-8477-38d49ed609a4","trusted":true}},{"cell_type":"markdown","source":"**<center><font size=5>RSNA-MICCAI Brain Tumor Classification</font></center>**\n\n<center><img src=\"https://lingualab.ca/fr/project/language-recovery-psa/featured_hu67ab33455cf328a3b8dbb37d23762824_484672_720x0_resize_lanczos_2.png\" alt=\"equal-2495950-1920\" border=\"0\" width=\"700\"></center>\n\n***\n\n**Table of Contents**\n- <a href='#intro'>1. Project overview and objectives</a> \n    - <a href='#survey'>1.1. The aim of the survey</a>\n    - <a href='#data'>1.2. Data set overview</a>\n- <a href='#bi'>2. </a>\n- <a href='#score'>3. </a>\n    - <a href='#method'>3.1.</a>\n    - <a href='#dl'>3.2. </a>\n    - <a href='#ra'>3.3. </a>","metadata":{}},{"cell_type":"markdown","source":"# Introduction\n\nThe RSNA-MICCAI Brain Tumor Radiogenomic Classification Contest is a multi-class classification problem, giving MRIs based on radiomic features, where the goal is to predict the presence of MGMT promoter methylation.\n\nThere are three classes: \n- LGG (low-grade glioma)\n- HGG (high-grade glioma) \n- WT (hemangioblastoma)\n\nThe dataset we will be working with consists of MRI datasets provided by the Radiological Society of North America (RSNA®) and the Medical Image Computing and Computer Assisted Intervention Society (the MICCAI Society). The images are provided in DICOM format and are accompanied by a CSV file containing radiomic features extracted from the images.\n\nHere's the competition [RSNA-MICCAI Brain Tumor Radiogenomic Classification](https://www.kaggle.com/competitions/rsna-miccai-brain-tumor-radiogenomic-classification/data?select=train_labels.csv)\n\n# Contributors\n\n- [David Goudard](https://www.kaggle.com/goudgoud)\n- [Louis-Marie Renaud](https://www.kaggle.com/louismarierenaud)\n- [Yannick Stephan](https://github.com/YanSteph)\n\n\n# Dataset\n\nThe exact mpMRI scans included are:\n- Fluid Attenuated Inversion Recovery (FLAIR)\n    * What it is: These are images that detect brain abnormalities, such as edema and inflammatory lesions. These images are sensitive to the detection of anomalies related to inflammatory and infectious diseases of the central nervous system.\n    * What it highlights: It helps to detect anomalies in the brain that might not be visible in other MRI sequences.\n    * These images allow for the detection of brain abnormalities related to inflammatory and infectious diseases of the central nervous system.\n- T1-weighted pre-contrast (T1w)\n    * What it is: These are images that highlight soft tissues, such as muscles and nerves, and are useful for visualizing normal brain structures.\n    * What it highlights: It allows the visualization of the normal brain structures and also helps in the detection of tumors and lesions.\n    * These images allow for the detection of brain tumors and lesions.\n- T1-weighted post-contrast (T1Gd)\n    * What it is: These are images that use a contrast agent to detect vascular anomalies, such as tumors and lesions, which are more visible after contrast agent administration.\n    * What it highlights: It enhances the visibility of vascular anomalies, such as tumors and lesions, making it easier to detect them.\n    * These images allow for the detection of vascular anomalies, such as tumors and lesions.\n- T2-weighted (T2)\n    * What it is: These images detect abnormalities related to demyelination, such as multiple sclerosis, as well as brain tumors and lesions.\n    * What it highlights: It helps in the detection of anomalies related to cerebrospinal fluid, such as cysts and brain tumors.\n    * These images allow for the detection of anomalies related to demyelination, brain tumors, lesions, and cerebrospinal fluid.","metadata":{"_uuid":"aab7ae79-4cb8-47ac-b9e7-c3fbc4bc2be1","_cell_guid":"ce27ea90-ac8e-4e38-82f9-cacfb5c86540","execution":{"iopub.status.busy":"2023-05-14T19:19:16.412499Z","iopub.execute_input":"2023-05-14T19:19:16.41328Z","iopub.status.idle":"2023-05-14T19:19:17.264665Z","shell.execute_reply.started":"2023-05-14T19:19:16.413115Z","shell.execute_reply":"2023-05-14T19:19:17.263011Z"},"trusted":true}},{"cell_type":"markdown","source":"# Necessary imports","metadata":{"_uuid":"ac2748aa-770b-4f0e-867a-385fa4653ca7","_cell_guid":"c8f9df88-64cb-48b7-bac0-8dc1f246bb4b","trusted":true}},{"cell_type":"code","source":"# Operating System and File System\nimport os \n\n# Data Manipulation and Analysis\nimport numpy as np  \nimport pandas as pd\n\n# Data Visualization\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\n# Warnings\nimport warnings  # For suppressing warnings\n\n# JSON Handling\nimport json  # For working with JSON data\n\n# Encoding and Decoding Binary Data\nimport base64  # For encoding and decoding binary data\n\n# Interactive Widgets and Display\nimport ipywidgets as widgets  # For creating interactive widgets in Jupyter Notebook\nfrom IPython.display import HTML, display  # For displaying HTML content\n\n# Deep Learning Framework\nimport torch  # For working with PyTorch deep learning framework\n\n# DICOM File Handling\nimport pydicom  # For reading DICOM files\nfrom pydicom import dcmread  # For reading DICOM files\n\n# Image Processing and Filtering\nimport SimpleITK as sitk  # For image filtering\nfrom PIL import Image  # For image processing using the Python Imaging Library (PIL)\n\n# Machine Learning and Data Splitting\nfrom sklearn.model_selection import train_test_split  # For splitting data into training and testing sets\n\nfrom scipy import stats\nfrom statsmodels.stats.diagnostic import lilliefors\nimport statsmodels.api as sm\n\n# Additional Libraries\n!pip install pyradiomics > /dev/null  # Installing the pyradiomics library for radiomics feature extraction\nimport radiomics  # For extracting radiomics features from medical images","metadata":{"_uuid":"e0d589d4-c03c-4b45-b5d4-221a8aa65a97","_cell_guid":"2433e3a1-2947-42cf-9fa9-50c9d5fdd4a5","execution":{"iopub.status.busy":"2023-05-21T18:25:19.930165Z","iopub.execute_input":"2023-05-21T18:25:19.930592Z","iopub.status.idle":"2023-05-21T18:25:33.364399Z","shell.execute_reply.started":"2023-05-21T18:25:19.930556Z","shell.execute_reply":"2023-05-21T18:25:33.362957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Configuration\n\n# Show all columns\npd.set_option('display.max_columns', None)\n# Suppressing Warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"26fe737b-9c30-4124-9837-108538073694","_cell_guid":"24bfb860-962d-4618-ae11-2e7846a870aa","execution":{"iopub.status.busy":"2023-05-21T18:25:33.368248Z","iopub.execute_input":"2023-05-21T18:25:33.368789Z","iopub.status.idle":"2023-05-21T18:25:33.37565Z","shell.execute_reply.started":"2023-05-21T18:25:33.368732Z","shell.execute_reply":"2023-05-21T18:25:33.374239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Methods definition","metadata":{}},{"cell_type":"code","source":"# ===============================================\n# Images methods\n# ===============================================\n\ndef get_processed_image(patient_id):\n    \"\"\"\n    Retrieves and processes the images for a given patient, grouping them for segmentation.\n\n    Args:\n        patient_id (str): The ID of the patient (BraTS21ID).\n\n    Returns:\n        numpy.ndarray: A processed image composed of the different images of the patient.\n    \"\"\"\n    # SEGMENTATION MODEL LIMITED TO 3 LAYERS\n    # T2W SKIPPED\n\n    # Paths for image sequences\n    t1w_path = f'{train_path}/{str(patient_id).zfill(5)}/T1w'\n    flair_path = f'{train_path}/{str(patient_id).zfill(5)}/FLAIR'\n    t1wce_path = f'{train_path}/{str(patient_id).zfill(5)}/T1wCE'\n    #t2w_path = f'{train_path}/{str(patient_id).zfill(5)}/T2w'\n\n    # Retrieve image sequences\n    t1w_image = sequence_filenames(t1w_path)\n    flair_image = sequence_filenames(flair_path)\n    t1wce_image = sequence_filenames(t1wce_path)\n    #t2w_image = sequence_filenames(t2w_path)\n\n    # Resampling\n    re_sampled_flair = re_sample_image(flair_image, t1w_image)\n    re_sampled_t1wce = re_sample_image(t1wce_image, t1w_image)\n    #re_sampled_t2w = re_sample_image(t2w_image, t1w_image)\n\n    # Normalization\n    t1w_array = normalize(sitk.GetArrayFromImage(t1w_image))\n    flair_array = normalize(sitk.GetArrayFromImage(re_sampled_flair))\n    t1wce_array = normalize(sitk.GetArrayFromImage(re_sampled_t1wce))\n    #t2w_array = normalize(sitk.GetArrayFromImage(re_sampled_t2w))\n\n    sequence_stacked = np.stack([t1w_array, flair_array, t1wce_array]) #, t2w_array])\n\n    central_slice = t1w_array.shape[0] // 2\n    rvb = sequence_stacked[:, central_slice, :, :].transpose(1, 2, 0)\n    image = Image.fromarray((rvb * 255).astype(np.uint8))\n    return np.array([np.moveaxis(np.array(image.resize((256, 256))), -1, 0)])\n\n\ndef sequence_filenames(path) :\n    \"\"\"\n    Retrieves a sequence of images for a given directory.\n\n    Args:\n        path (str): The path to the directory containing the DICOM data set.\n\n    Returns:\n        SimpleITK.Image: A sequence of images corresponding to the DICOM files in the directory.\n\n    Raises:\n        FileNotFoundError: If the specified path does not exist.\n    \"\"\"\n    filenames = sitk_reader.GetGDCMSeriesFileNames(path)\n    sitk_reader.SetFileNames(filenames)\n    image = sitk_reader.Execute()\n    \n    return image    \n\ndef normalize(dataset) :\n    \"\"\"\n    Normalizes the data obtained from the images.\n\n    Args:\n        dataset (numpy.ndarray): The dataset to be normalized.\n\n    Returns:\n        numpy.ndarray: The normalized dataset.\n    \"\"\"\n    return (dataset - np.min(dataset)) / (np.max(dataset) - np.min(dataset))\n\n\ndef re_sample_image(image, ref_img):\n    \"\"\"\n    Resamples the image to match the dimensions and properties of the reference image.\n\n    Args:\n        image (SimpleITK.Image): The image to be resampled.\n        ref_img (SimpleITK.Image): The reference image used for resampling.\n\n    Returns:\n        SimpleITK.Image: The resampled image.\n    \"\"\"\n    re_sampler = sitk.ResampleImageFilter()\n    re_sampler.SetReferenceImage(ref_img)\n    re_sampler.SetDefaultPixelValue(image.GetPixelIDValue())\n    re_sampler.SetInterpolator(sitk.sitkLinear)\n    re_sampler.SetOutputSpacing(ref_img.GetSpacing())\n    re_sampler.SetOutputDirection(ref_img.GetDirection())\n    re_sampler.SetOutputOrigin(ref_img.GetOrigin())\n    re_sampler.SetSize(ref_img.GetSize())\n    re_sampler.SetTransform(sitk.AffineTransform(image.GetDimension()))\n    re_sampled_image = re_sampler.Execute(image)\n    \n    return re_sampled_image\n\ndef segmentation_process(image_resized):\n    \"\"\"\n    Obtains the segmented image.\n\n    Args:\n        image_resized (numpy.ndarray): The resized image.\n\n    Returns:\n        numpy.ndarray: The segmented image.\n    \"\"\"\n    segmentation = segmentation_model(torch.Tensor(image_resized))\n    return segmentation\n    \n# ===============================================\n# Dataset creation methods\n# ===============================================\n\ndef init_dataset_radiomics() :\n    \"\"\"\n    Initializes the DataFrame structures for radiomics data acquisition.\n\n    Returns:\n        None\n    \"\"\"\n    global df_shapes\n    global df_textures\n    global df_first_orders_features\n    \n    df_shapes_columns = ['ID','BraTS21ID','MeshSurface','PixelSurface','Perimeter','PerimeterSurfaceRatio','Sphericity',\n                              'SphericalDisproportion','MaximumDiameter','MajorAxisLength','MinorAxisLenth','Elongation']\n    df_shapes = pd.DataFrame(columns=df_shapes_columns) \n\n\n    df_textures_columns = ['ID','Autocorrelation', 'ClusterProminence', 'ClusterShade', 'ClusterTendency', 'Contrast', \n                           'Correlation', 'DifferenceAverage', 'DifferenceEntropy', 'DifferenceVariance', 'Id', 'Idm', \n                           'Idmn', 'Idn', 'Imc1', 'Imc2', 'InverseVariance', 'JointAverage', 'JointEnergy', 'JointEntropy', \n                           'MCC', 'MaximumProbability', 'SumAverage', 'SumEntropy', 'SumSquares']\n    df_textures = pd.DataFrame(columns=df_textures_columns) \n\n\n    df_first_orders_features_columns=['ID','10Percentile', '90Percentile', 'Energy', 'Entropy', 'InterquartileRange', 'Kurtosis', \n                                      'Maximum', 'MeanAbsoluteDeviation', 'Mean', 'Median', 'Minimum', 'Range', 'RobustMeanAbsoluteDeviation', \n                                      'RootMeanSquared', 'Skewness', 'TotalEnergy', 'Uniformity', 'Variance']\n    df_first_orders_features = pd.DataFrame(columns=df_first_orders_features_columns) \n    \n\ndef add_patient_data(ID,img_resized,segmentation) :\n    \"\"\"\n    Adds data from the specified patient's images to the analysis dataset.\n\n    Args:\n        ID (int): The ID of the patient.\n        img_resized (numpy.ndarray): Resized image of the patient.\n        segmentation (torch.Tensor): Segmentation of the patient's image.\n\n    Returns:\n        None\n    \"\"\"\n    global df_shapes\n    global df_textures\n    global df_first_orders_features\n    \n    # shape\n    results = radiomics.shape2D.RadiomicsShape2D(\n        sitk.GetImageFromArray(img_resized), \n        sitk.GetImageFromArray(np.array([\n            segmentation[0][0].detach().cpu().numpy() > 0.5\n        ]).astype(np.uint8)),\n        force2D=True\n    )\n    \n    shape2D = {}\n    shape2D['ID'] = int(ID)\n    shape2D['BraTS21ID'] = int(ID)\n    shape2D['MeshSurface'] = results.getMeshSurfaceFeatureValue()\n    shape2D['PixelSurface'] = results.getPixelSurfaceFeatureValue()\n    shape2D['Perimeter'] = results.getPerimeterFeatureValue()\n    shape2D['PerimeterSurfaceRatio'] = results.getPerimeterSurfaceRatioFeatureValue()\n    shape2D['Sphericity'] = results.getSphericityFeatureValue()\n    shape2D['SphericalDisproportion'] = results.getSphericalDisproportionFeatureValue()\n    shape2D['MaximumDiameter'] = results.getMaximumDiameterFeatureValue()\n    shape2D['MajorAxisLength'] = results.getMajorAxisLengthFeatureValue()\n    shape2D['MinorAxisLenth'] = results.getMinorAxisLengthFeatureValue()\n    shape2D['Elongation'] = results.getElongationFeatureValue()\n    \n    df_shapes=df_shapes.append(shape2D,ignore_index=True)\n    \n    # GLCM\n    results=radiomics.glcm.RadiomicsGLCM(\n        sitk.GetImageFromArray(img_resized[0,0,:,:].reshape(1, 256, 256)), \n        sitk.GetImageFromArray(np.array([\n            segmentation[0][0].detach().cpu().numpy() > 0.5\n        ]).astype(np.uint8)),\n        force2D=True\n    )\n\n    results.enableAllFeatures()\n    res = results.execute()\n    res['ID']=int(ID)\n\n    df_textures=df_textures.append(res,ignore_index=True)\n    \n    # First-orders features\n    results =  radiomics.firstorder.RadiomicsFirstOrder(\n        sitk.GetImageFromArray(img_resized[0,0,:,:].reshape(1, 256, 256)), \n        sitk.GetImageFromArray(np.array([\n            segmentation[0][0].detach().cpu().numpy() > 0.5\n        ]).astype(np.uint8)),\n        force2D=True\n    )\n\n    results.enableAllFeatures()\n    res = results.execute()\n    res['ID']=int(ID)\n\n    df_first_orders_features=df_first_orders_features.append(res,ignore_index=True)\n    \n    \n# ===============================================\n# Show methods\n# ===============================================\n\ndef show_segmentation(img_src,segmentation) :\n    \"\"\"\n    Displays the resized source images and the segmentation image in a single line.\n\n    Args:\n        img_src (numpy.ndarray): Resized source images.\n        segmentation (torch.Tensor): Segmentation image.\n\n    Returns:\n        None\n    \"\"\"\n    titles=['T1w','FLAIR','T1wce'] #,'T2w']\n    for i in range(3):\n        plt.subplot(1,4,1+i)\n        plt.imshow(img_src[0, i])\n        plt.title(titles[i])\n        plt.xticks([])\n        plt.yticks([])\n    \n    plt.subplot(1,4,4)\n    plt.imshow(segmentation.detach().numpy()[0,0])\n    plt.title('Segmentation')\n    plt.xticks([])\n    plt.yticks([])\n\n    plt.tight_layout()\n    plt.show()\n    \ndef show_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):\n    \"\"\"\n    Displays a download link for a DataFrame as a CSV file.\n\n    Args:\n        df (pandas.DataFrame): The DataFrame to be downloaded.\n        title (str): The title of the download link (default: \"Download CSV file\").\n        filename (str): The name of the downloaded file (default: \"data.csv\").\n\n    Returns:\n        None\n    \"\"\"\n    csv = df.to_csv()\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload, title=title, filename=filename)\n    display(HTML(html))\n    \n# ===============================================\n# Analysis\n# ===============================================\n\ndef filter_correlation_matrix(correlation_matrix, correlation_threshold):\n    \"\"\"\n    Filters a correlation matrix by keeping only the absolute values greater than or equal to the correlation threshold.\n\n    Args:\n        correlation_matrix (pd.DataFrame): The correlation matrix.\n        correlation_threshold (float): The correlation threshold for filtering the matrix.\n\n    Returns:\n        pd.DataFrame: The filtered correlation matrix.\n\n    \"\"\"\n    filtered_correlation_matrix = correlation_matrix[abs(correlation_matrix) >= correlation_threshold]\n\n    return filtered_correlation_matrix\n\ndef find_highly_correlated_groups(correlation_matrix, correlation_threshold = 0.8, filter_duplicated_group = True, convert_indices_to_column_names = True):\n    \"\"\"\n    Finds groups of highly correlated variables from a correlation matrix.\n\n    Args:\n        correlation_matrix (pd.DataFrame): The correlation matrix.\n        correlation_threshold (float): The correlation threshold to consider as highly correlated.\n        filter_duplicated_group (bool): Indicates whether to filter out duplicated values in the correlated groups.\n        convert_indices_to_column_names (bool): Indicates whether to convert indices to column names.\n\n    Returns:\n        List[List[str]]: A list of groups, where each group contains the names of variables that are highly correlated.\n\n    \"\"\"\n    n = correlation_matrix.shape[0]  # Number of variables in the correlation matrix\n    groups_correlated = []  # List to store the correlated groups\n    \n    # Retrieve column names\n    column_names = correlation_matrix.columns\n    \n    # Traverse each variable\n    for i in range(n):\n        if column_names[i] not in [column_names[v] for g in groups_correlated for v in g]:  # Check if the variable has already been added to a group\n            group = [i]  # Create a new group containing the current variable (i)\n            for j in range(i+1, n):\n                if column_names[j] not in [column_names[v] for g in groups_correlated for v in g]:  # Check if the variable has already been added to a group\n                    correlation = correlation_matrix.iloc[i, j]  # Retrieve the correlation between variables i and j\n                    if abs(correlation) >= correlation_threshold:  # Strong correlation condition (adjust as needed)\n                        group.append(j)  # Add variable j to the group\n            \n            groups_correlated.append(group)  # Add the group to the list of correlated groups\n    \n    # Filter out duplicated values in the correlated groups\n    if filter_duplicated_group:\n        filtered_groups_correlated = []\n        for group in groups_correlated:\n            filtered_group = list(set(group))  # Convert to a set to eliminate duplicates, then convert back to a list\n            filtered_groups_correlated.append(filtered_group)\n        groups_correlated = filtered_groups_correlated # Reset by new one\n    \n    # Convert indices to column names\n    if convert_indices_to_column_names:\n        groups_correlated = [[column_names[i] for i in group] for group in groups_correlated]\n    \n    return groups_correlated\n\ndef fonc_test_normality(df,graphic=True) : \n\n    describe = df.describe()\n    \n    for col in df.columns :\n\n        describe.loc['skewness',col] = stats.skew(df[col])\n        describe.loc['kurtosis', col] = stats.kurtosis(df[col],fisher=False)#Vrai kurtosis\n        describe.loc['excess_kurtosis',col] = stats.kurtosis(df[col])#Vrai kurtosis\n        shapiro_test =  stats.shapiro(df[col])[1]\n        describe.loc['shapiro_test',col] = shapiro_test\n        describe.loc['normalite',col] = 'Oui' if shapiro_test > 0.05 else 'Non'\n\n        if graphic : \n            figure_size = (6, 2)\n\n            fig = plt.figure(figsize=figure_size)\n\n            plt.subplot(1,3,1)\n            sns.histplot(df[col], kde=True)\n            plt.title('Histogramme de {}'.format(col),fontsize=8)\n            plt.xlabel('Valeur',fontsize=7)\n            plt.ylabel('Fréquence',fontsize=7)\n            plt.plot(describe.loc['mean',col],0, marker=\"o\", color=\"red\")\n\n            plt.subplot(1,3,2)\n            plt.boxplot(x=df[col])\n            plt.title('Boxplot de {}'.format(col),fontsize=8)\n            #plt.xlabel('Valeur')\n\n            plt.subplot(1,3,3)\n            stats.probplot(df[col], plot=plt)\n            plt.title('Q-Q plot pour {}'.format(col),fontsize=8)\n            plt.xlabel('Quantile théorique',fontsize=7)\n            plt.ylabel('Valeurs ordonnées',fontsize=7)\n            plt.tight_layout()\n            plt.show()\n\n    return describe","metadata":{"execution":{"iopub.status.busy":"2023-05-21T18:25:33.37794Z","iopub.execute_input":"2023-05-21T18:25:33.378343Z","iopub.status.idle":"2023-05-21T18:25:33.443721Z","shell.execute_reply.started":"2023-05-21T18:25:33.378308Z","shell.execute_reply":"2023-05-21T18:25:33.442404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Paths","metadata":{"_uuid":"ccc63aeb-5fef-48e0-9a72-94d586d4e02d","_cell_guid":"3035e91b-c00f-417e-9783-8c1eef38d40f","trusted":true}},{"cell_type":"code","source":"path_rsna_brain_tumor_classification = \"../input/rsna-miccai-brain-tumor-radiogenomic-classification/\"\n\ntrain_path = path_rsna_brain_tumor_classification + \"train/\"\ntrain_label_file = path_rsna_brain_tumor_classification + '/train_labels.csv'\n\n# @TODO define path like genere\npath = \"../input/rsna-miccai-brain-tumor-segmentation-pytorch-unet/\"\ndataset_path = \"/kaggle/input/rsna-miccai-brain-tumor-segmentation-pytorch-unet/rsna_miccai_brain_tumor_brain_segmentation_pytorch_unet.csv\"\n#path + \"rsna_miccai_brain_tumor_brain_segmentation_pytorch_unet.csv/\"","metadata":{"_uuid":"fce3f0dc-3d0c-408f-a817-fd85732b8e13","_cell_guid":"2d7bd81f-1902-4546-bee3-8452ea3c4ec1","execution":{"iopub.status.busy":"2023-05-21T18:25:33.447899Z","iopub.execute_input":"2023-05-21T18:25:33.448398Z","iopub.status.idle":"2023-05-21T18:25:33.455705Z","shell.execute_reply.started":"2023-05-21T18:25:33.448353Z","shell.execute_reply":"2023-05-21T18:25:33.454215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reading Data","metadata":{"_uuid":"ec77a0c3-744c-4b7d-aa5d-50b69250ae8d","_cell_guid":"55e86934-205d-4f42-91a4-00d007325b1f","trusted":true}},{"cell_type":"code","source":"# Dataset of the project, explanation in next section.\ndataset = pd.read_csv(train_label_file)\nsamp_subm = pd.read_csv(path_rsna_brain_tumor_classification + 'sample_submission.csv')","metadata":{"_uuid":"d1745d69-4f19-4cf9-bef2-4618d9a52615","_cell_guid":"625434ea-19b2-400f-8c5c-536263d685c7","execution":{"iopub.status.busy":"2023-05-21T18:25:33.457155Z","iopub.execute_input":"2023-05-21T18:25:33.458121Z","iopub.status.idle":"2023-05-21T18:25:33.478315Z","shell.execute_reply.started":"2023-05-21T18:25:33.458086Z","shell.execute_reply":"2023-05-21T18:25:33.477109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<hr>","metadata":{"_uuid":"0c00dbb0-db46-4952-ac89-9907f5384136","_cell_guid":"b52251e3-6e99-4686-9ee8-54ba7a7ae504","trusted":true}},{"cell_type":"markdown","source":"# Dataset in the state exploration","metadata":{"_uuid":"975099a9-fe03-49bd-af97-af5e5182c511","_cell_guid":"9fe1f5dd-4c72-428c-956c-288f3b7867b7","trusted":true}},{"cell_type":"markdown","source":"The **\"train/\"** directory contains the training files for the competition. Each top-level directory represents a subject, and the **\"train_labels.csv\"** file contains the corresponding targets for each subject, indicating the presence of MGMT promoter methylation.\n\nℹ️ **Note:** However, report on main contest page, there are unexpected problems with the following three cases in the training dataset: [00109, 00123, 00709].","metadata":{"_uuid":"c174e118-bf74-46b0-9510-379dfb31dc98","_cell_guid":"a6cd9788-973a-427e-abc2-ef885bc1a5cf","trusted":true}},{"cell_type":"code","source":"print('Samples of train folder:', len(dataset))","metadata":{"_uuid":"e43848b8-576d-4c50-9543-b4ae79cfad51","_cell_guid":"4be4773f-6454-4a16-9f11-88f70e105282","execution":{"iopub.status.busy":"2023-05-21T18:25:33.480009Z","iopub.execute_input":"2023-05-21T18:25:33.480359Z","iopub.status.idle":"2023-05-21T18:25:33.486577Z","shell.execute_reply.started":"2023-05-21T18:25:33.48033Z","shell.execute_reply":"2023-05-21T18:25:33.485286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.head(10)","metadata":{"_uuid":"8fe50b08-448d-4c60-aa1a-214f27b06431","_cell_guid":"6c8a3874-fe30-497f-badc-2f44ae6cd5f5","execution":{"iopub.status.busy":"2023-05-21T18:25:33.488211Z","iopub.execute_input":"2023-05-21T18:25:33.488678Z","iopub.status.idle":"2023-05-21T18:25:33.506831Z","shell.execute_reply.started":"2023-05-21T18:25:33.488636Z","shell.execute_reply":"2023-05-21T18:25:33.505604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The \"train_labels.csv\" file.","metadata":{"_uuid":"626012c0-6fcb-4687-b8a1-c09d1c76ae3b","_cell_guid":"067c6bab-4a55-4b02-a486-c8eef45ee4a0","trusted":true}},{"cell_type":"code","source":"plt.figure(figsize=(5, 5))\nsns.countplot(data=dataset, x=\"MGMT_value\")\nplt.title(\"Distribution of MGMT values\")\nplt.xlabel(\"MGMT Value\")\nplt.xticks([0, 1], [\"Not Present\", \"Present\"])\nplt.show()","metadata":{"_uuid":"e4465c3a-08f1-4ac7-bab1-06a29612057b","_cell_guid":"4d2fb47d-54f0-4840-a5fe-8d7c9214a184","execution":{"iopub.status.busy":"2023-05-21T18:25:33.508873Z","iopub.execute_input":"2023-05-21T18:25:33.509292Z","iopub.status.idle":"2023-05-21T18:25:33.752178Z","shell.execute_reply.started":"2023-05-21T18:25:33.509257Z","shell.execute_reply":"2023-05-21T18:25:33.751062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The **\"test/\"** directory contains the test files. For each subject in the test data, there is no file containing the methylation targets, so these values must be predicted. The **\"sample_submission.csv\"** file is an example of a correctly formatted submission file, with MGMT values of **0.5** for each subject.\n\nOverall, the task of the competition is to predict the presence of MGMT promoter methylation for each subject in the test data.\n\nℹ️ **Note:** We deduce that we have to separate the sets of given train into part two part train and test for training.","metadata":{"_uuid":"40dd9032-a462-466f-9c5e-a844fab7e7a0","_cell_guid":"1b49a738-6156-415e-9c7b-2f330bb0c6a6","trusted":true}},{"cell_type":"code","source":"samp_subm.head(1)","metadata":{"_uuid":"00f80b44-29ef-4d8a-a817-cd3e8066b39e","_cell_guid":"f0e04864-3bca-4b08-a0c9-6be1ed58fdb4","execution":{"iopub.status.busy":"2023-05-21T18:25:33.75378Z","iopub.execute_input":"2023-05-21T18:25:33.754166Z","iopub.status.idle":"2023-05-21T18:25:33.764811Z","shell.execute_reply.started":"2023-05-21T18:25:33.754135Z","shell.execute_reply":"2023-05-21T18:25:33.763166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Folders content","metadata":{"_uuid":"4b5c64d4-21c2-4d4b-9ecc-9830d7a7fed8","_cell_guid":"73299e0c-dd3c-469b-afec-a5643c34fc12","trusted":true}},{"cell_type":"code","source":"# Extract first train sample\nfirst_folder = str(dataset.loc[0, 'BraTS21ID']).zfill(5) + \"/\"\n\n# Folders content\nprint(\n    \"Folders content for all patients:\", \n        json.dumps(os.listdir(train_path + first_folder), indent=4)\n)","metadata":{"_uuid":"7ac2bb3d-73a0-4b00-adca-1d5c0ca9eb2a","_cell_guid":"afd26a83-9b4a-423f-a9b8-75e375a58c61","execution":{"iopub.status.busy":"2023-05-21T18:25:33.771481Z","iopub.execute_input":"2023-05-21T18:25:33.772792Z","iopub.status.idle":"2023-05-21T18:25:33.781749Z","shell.execute_reply.started":"2023-05-21T18:25:33.772744Z","shell.execute_reply":"2023-05-21T18:25:33.780205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### First patient exploration\n\nIn the first Dataset of the patient, we will explore the images contained in ['T2w', 'T1wCE', 'T1w', 'FLAIR'] of the first patient.","metadata":{"_uuid":"d07134fc-d6a6-4ef5-ba53-38224751f5c5","_cell_guid":"2ee8be5f-696e-4b21-8ceb-177cde40a9c1","trusted":true}},{"cell_type":"code","source":"print('Number of FLAIR images:', len(os.listdir(train_path + first_folder +'FLAIR')))\nprint('Number of T1w images:', len(os.listdir(train_path + first_folder + 'T1w')))\nprint('Number of T1wCE images:', len(os.listdir(train_path + first_folder + 'T1wCE')))\nprint('Number of T2w images:', len(os.listdir(train_path + first_folder + 'T2w')))","metadata":{"_uuid":"803ef2f5-0ebd-434f-9c36-054ba6331169","_cell_guid":"edde569f-8b0e-4b13-b9fb-587e34a6a42c","execution":{"iopub.status.busy":"2023-05-21T18:25:33.783912Z","iopub.execute_input":"2023-05-21T18:25:33.784759Z","iopub.status.idle":"2023-05-21T18:25:33.797084Z","shell.execute_reply.started":"2023-05-21T18:25:33.784716Z","shell.execute_reply":"2023-05-21T18:25:33.795897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ℹ️ **Summary:** \n* We deduce that we have to separate the sets of given train into part two part train and test for training.\n* Report on main contest page, there are unexpected problems with the following three cases in the training dataset: [00109, 00123, 00709], we exclude this data.\n* Exclusion of \"/test\" folder.","metadata":{"_uuid":"0dd5b7d0-8963-42db-b72b-c39c0745a1b6","_cell_guid":"020a9427-df6c-4efe-a0c2-15ff8428c58d","trusted":true}},{"cell_type":"markdown","source":"----","metadata":{"_uuid":"2f361738-71af-4e9b-a578-9ada35ab56c9","_cell_guid":"01eef3f2-4093-4276-9d11-7643ffe926f3","trusted":true}},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"# Brain segmentation with mateuszbuda brain segmentation pytorch unet\n\n#### Why\nThe **\"mateuszbuda_brain-segmentation-pytorch_unet\"** library was utilized to obtain data for our brain dataset. This library is based on the Unet neural network architecture and specifically designed for brain segmentation from medical images.\n\nBy leveraging the capabilities of this library, accurate brain segmentation was achieved on the images within our dataset. Segmentation is a critical task in medical imaging as it enables the extraction of precise information about different regions or classes, in this case, brain structures.\n\nThe selection of the **\"mateuszbuda_brain-segmentation-pytorch_unet\"** library was based on its exceptional performance and user-friendly nature. It provides an efficient implementation of the Unet architecture, renowned for its success in biomedical image segmentation. Consequently, our project was able to deliver reliable and accurate results for brain segmentation.\n\nIn conclusion, the utilization of the **\"mateuszbuda_brain-segmentation-pytorch_unet\"** library played a pivotal role in acquiring accurate brain segmentation data for our dataset. By leveraging this library, we efficiently segmented medical images and extracted valuable information to further our project's objectives.\n\nSource: [mateuszbuda_brain-segmentation-pytorch_unet on PyTorch Hub](https://pytorch.org/hub/mateuszbuda_brain-segmentation-pytorch_unet/)\n\n#### Library\n\nTo achieve tumor segmentation, the U-Net for Brain MRI model will be employed.\n\nU-Net for Brain MRI is a convolutional neural network model specifically designed for segmenting brain MRI images. It features a U-shaped architecture with branch connections, comprising four levels of blocks. Each block consists of two convolution layers with batch normalization, ReLU activation function, and an encoding part with a max pooling layer, while the decoding part utilizes up-convolution. The number of convolution filters varies across the model's levels, ranging from 32 to 256.\n\nTo utilize the model, an input brain MRI image with three channels corresponding to pre-contrast, FLAIR, and post-contrast sequences should be provided. The image should be scaled to a size of 256x256 pixels and normalized using the z-score method per volume.\n\nThe pre-trained U-Net model produces a single-channel probability map indicating anomalous regions in the input image. By applying an appropriate threshold, this probability map can be converted into a binary segmentation mask.\n\nIn summary, U-Net for Brain MRI is a pre-trained model capable of automatically segmenting abnormalities in brain MRI images. Its application extends to various medical imaging tasks, including brain tumor detection and analysis.\n\n\nTo perform shape analysis and extract relevant features, the **\"radiomics.shape2D.RadiomicsShape2D\"** class will be utilized.\n\nSource: [Radiomics.shape2D.RadiomicsShape2D ](https://pyradiomics.readthedocs.io/en/latest/features.html#module-radiomics.shape2D)","metadata":{"_uuid":"062dda8d-a1df-46e1-81b0-ea5088cf5c0a","_cell_guid":"5a5992eb-1386-45c8-84c5-9eaeb7d689d2","trusted":true}},{"cell_type":"code","source":"# Flag to skip brain segmentation with PyTorch UNet\n# If set to True, we will import the dataset that has already been generated\nskip_brain_segmentation_pytorch_unet = True","metadata":{"_uuid":"f441bec0-e5c3-45d6-ad89-e8c735e2368c","_cell_guid":"ea63ae1d-5be3-4d8d-9e98-4ac8c7870152","execution":{"iopub.status.busy":"2023-05-21T18:25:33.798996Z","iopub.execute_input":"2023-05-21T18:25:33.800055Z","iopub.status.idle":"2023-05-21T18:25:33.805786Z","shell.execute_reply.started":"2023-05-21T18:25:33.800011Z","shell.execute_reply":"2023-05-21T18:25:33.804559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Initialisation","metadata":{"_uuid":"400e0ad7-2e67-474c-9ced-822f0c02b5ba","_cell_guid":"01bcf72a-5431-4e63-b18b-53688dae8a84","trusted":true}},{"cell_type":"markdown","source":"Load mateuszbuda/brain-segmentation-pytorch, U-Net with batch normalization for biomedical image segmentation with pretrained weights for abnormality segmentation in brain MRI","metadata":{"_uuid":"c0e6428c-e05f-4fe6-8dc1-5d95f8374afa","_cell_guid":"c25d5f5f-68fb-42cd-a89d-c7dfc7d1165a","trusted":true}},{"cell_type":"code","source":"# Load mateuszbuda/brain-segmentation-pytorch, U-Net with batch normalization for biomedical image segmentation with pretrained weights for abnormality segmentation in brain MRI\nsegmentation_model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', in_channels=3, out_channels=1, init_features=32, pretrained=True, trust_repo=False)","metadata":{"_uuid":"155bd899-aaff-4e7a-8d9a-3ba04936fbc6","_cell_guid":"345309d9-bf0d-42b4-ac46-7f0e220eb7c9","execution":{"iopub.status.busy":"2023-05-21T18:25:33.807631Z","iopub.execute_input":"2023-05-21T18:25:33.808366Z","iopub.status.idle":"2023-05-21T18:25:38.188143Z","shell.execute_reply.started":"2023-05-21T18:25:33.808311Z","shell.execute_reply":"2023-05-21T18:25:38.186958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define \"reader\"\n# Read serie of image files into a SimpleTK image\nsitk_reader = sitk.ImageSeriesReader()\nsitk_reader.LoadPrivateTagsOn()","metadata":{"_uuid":"64b5ea0b-aa29-4cb9-987f-82eb15a4ab97","_cell_guid":"4a802aa0-5472-446d-ab98-fd1be7fb27fc","execution":{"iopub.status.busy":"2023-05-21T18:25:38.189891Z","iopub.execute_input":"2023-05-21T18:25:38.190385Z","iopub.status.idle":"2023-05-21T18:25:38.197673Z","shell.execute_reply.started":"2023-05-21T18:25:38.190353Z","shell.execute_reply":"2023-05-21T18:25:38.196332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataset creation execution phase\n\nAll patients from the train_labels.csv file will be used.","metadata":{"_uuid":"0e14f6e6-e0db-4bbe-8101-cebce269a187","_cell_guid":"8ec4981f-f98f-4639-a62b-8c15ee786b11","trusted":true}},{"cell_type":"code","source":"if skip_brain_segmentation_pytorch_unet:\n    dataset = pd.read_csv(dataset_path)\n    \nelse:\n    loader = widgets.IntProgress(min=0, max=len(dataset), description='Loading:')\n    display(loader)\n    \n    # Empty creation of datasets\n    init_dataset_radiomics()\n\n    for i in dataset.BraTS21ID :\n        loader.value += 1\n        img_resized = get_processed_image(i)\n        segmentation = segmentation_process(img_resized)\n        add_patient_data(i, img_resized, segmentation)\n\n    # Join the 3 datasets\n    df_shapes = df_shapes.set_index('ID')\n    df_textures = df_textures.set_index('ID')\n    df_first_orders_features = df_first_orders_features.set_index('ID')\n\n    df = df_shapes.join(df_textures).join(df_first_orders_features)\n\n    # Define 'BraTS21ID' column as integer IDs\n    df['BraTS21ID'] = df['BraTS21ID'].astype(int)\n    \n    # Merge the old dataset with the new one\n    dataset = pd.merge(dataset, df, left_on='BraTS21ID', right_on='BraTS21ID')\n    dataset.rename(columns={'BraTS21ID': 'ID'}, inplace=True)\n    \n# Patient BraTS21ID now is ID, and ID of Dataset\ndataset = dataset.set_index('ID')\nshow_download_link(dataset)","metadata":{"_uuid":"5d9f4fbb-b271-4c71-a72c-558714129b1b","_cell_guid":"efe065fc-352d-40c3-a926-00aab7146fda","execution":{"iopub.status.busy":"2023-05-21T18:25:38.200179Z","iopub.execute_input":"2023-05-21T18:25:38.201461Z","iopub.status.idle":"2023-05-21T18:25:38.304481Z","shell.execute_reply.started":"2023-05-21T18:25:38.201403Z","shell.execute_reply":"2023-05-21T18:25:38.303468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<hr>","metadata":{"_uuid":"72d0c8ee-519b-41ad-b3c4-b1ab69cb704b","_cell_guid":"7405840e-518b-4685-8526-9efbeda30ede","trusted":true}},{"cell_type":"markdown","source":"# Dataset exploration","metadata":{"_uuid":"8df47077-5af6-4058-a60b-ac9e921e0df3","_cell_guid":"4f8b0432-3841-41bb-ad55-84da23a5ede5","trusted":true}},{"cell_type":"markdown","source":"These features provide information about various properties of brain MRI images, such as shape, texture, and grayscale statistics. They are commonly used for analysis and classification of medical images to aid in the detection and characterization of brain pathologies.\n\nHere is the requested list of features extracted from brain MRI images:\n\n**Shape Features:**\n\n* **ID:** Sample identifier.\n* **MeshSurface:** Mesh surface representing the object's surface using a three-dimensional mesh.\n* **PixelSurface:** Surface in pixels representing the object's surface using pixels.\n* **Perimeter:** Perimeter of the object, which is the length of the line surrounding the object.\n* **PerimeterSurfaceRatio:** Ratio of perimeter to surface, which can provide an indication of the object's shape.\n* **Sphericity:** Sphericity, measuring how closely the object resembles a perfect sphere.\n* **SphericalDisproportion:** Spherical disproportion, measuring the difference between the object's shape and a perfect sphere.\n* **MaximumDiameter:** Maximum diameter, which is the greatest distance between two points of the object.\n* **MajorAxisLength:** Major axis length, which is the length of the object's principal axis.\n* **MinorAxisLength:** Minor axis length, which is the length of the object's secondary axis.\n* **Elongation:** Elongation, measuring the stretching of the object.\n\n**Texture Features:**\n\n* **ID:** Sample identifier.\n* **Autocorrelation:** Autocorrelation, measuring the similarity between grayscale levels of an image at different positions.\n* **ClusterProminence:** Cluster prominence, measuring the asymmetry and regularity of pixel values within a cluster.\n* **ClusterShade:** Cluster shade, measuring the symmetry of pixel values within a cluster.\n* **ClusterTendency:** Cluster tendency, measuring the similarity of pixel values within a cluster.\n* **Contrast:** Contrast, measuring the brightness differences between neighboring pixels.\n* **Correlation:** Correlation, measuring the linear relationship between grayscale levels of an image in different directions.\n* **DifferenceAverage:** Difference average, measuring the average differences between grayscale levels of neighboring pixels.\n* **DifferenceEntropy:** Difference entropy, measuring the amount of information in the differences between grayscale levels of neighboring pixels.\n* **DifferenceVariance:** Difference variance, measuring the variability of differences between grayscale levels of neighboring pixels.\n* **Id, Idm, Idmn, Idn, Imc1, Imc2:** These texture-specific features are computed from gray-level co-occurrence matrices and measure different properties of the distribution of gray levels in the image.\n* **InverseVariance:** Inverse variance, measuring the reciprocity of gray-level variance in the image.\n* **JointAverage:** Joint average, measuring the average gray levels in neighborhood relationships.\n* **JointEnergy:** Joint energy, measuring the sum of squared joint gray level values.\n* **JointEntropy:** Joint entropy, measuring the amount of information contained in joint gray level values.\n* **MCC:** Maximum correlation coefficient, measuring the maximum correlation between grayscale levels of an image in different directions.\n* **MaximumProbability:** Maximum probability, measuring the maximum probability of joint grayscale values.\n* **SumAverage:** Sum average, measuring the average sum of joint gray level values.\n* **SumEntropy:** Sum entropy, measuring the amount of information contained in the sums of joint gray level values.\n* **SumSquares:** Sum squares, measuring the sum of squared joint gray level values.\n\n**First-Order Features:**\n\n* **ID:** Sample identifier.\n* **MGMT_value:** Presence of MGMT.\n* **10Percentile:** 10th percentile, representing the value below which 10% of the pixels are found.\n* **90Percentile:** 90th percentile, representing the value below which 90% of the pixels are found.\n* **Energy:** Energy, measuring the sum of squared grayscale levels of pixels.\n* **Entropy:** Entropy, measuring the amount of information contained in the grayscale levels of the image.\n* **InterquartileRange:** Interquartile range, which is the difference between the 75th and 25th percentiles, providing","metadata":{"_uuid":"18f546e6-dc46-4f18-a816-7333137672d5","_cell_guid":"caf0f490-1bba-4ba8-956c-04b653d797a8","trusted":true}},{"cell_type":"code","source":"dataset.head()","metadata":{"_uuid":"85e76c14-7413-4216-b9dc-d677bacb89ba","_cell_guid":"5fe62e60-ddc2-4000-962a-2f638b18831c","execution":{"iopub.status.busy":"2023-05-21T18:25:38.306141Z","iopub.execute_input":"2023-05-21T18:25:38.306865Z","iopub.status.idle":"2023-05-21T18:25:38.368911Z","shell.execute_reply.started":"2023-05-21T18:25:38.306826Z","shell.execute_reply":"2023-05-21T18:25:38.367741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.info()","metadata":{"_uuid":"1db7557d-6a1a-40fa-a93a-c2fa8a051ab9","_cell_guid":"c4539658-1709-4ed0-adba-3da12ceb978b","execution":{"iopub.status.busy":"2023-05-21T18:25:38.370438Z","iopub.execute_input":"2023-05-21T18:25:38.370818Z","iopub.status.idle":"2023-05-21T18:25:38.389491Z","shell.execute_reply.started":"2023-05-21T18:25:38.370787Z","shell.execute_reply":"2023-05-21T18:25:38.388311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.describe()","metadata":{"_uuid":"ba665176-fd9e-468e-8c64-9530ef6788a9","_cell_guid":"91c51839-0b42-435a-879c-06a383dea38d","execution":{"iopub.status.busy":"2023-05-21T18:25:38.390742Z","iopub.execute_input":"2023-05-21T18:25:38.391064Z","iopub.status.idle":"2023-05-21T18:25:38.591607Z","shell.execute_reply.started":"2023-05-21T18:25:38.391036Z","shell.execute_reply":"2023-05-21T18:25:38.590405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ℹ️ **Summary:**\n* No null values\n* The variables **\"MGMT_value\", \"MeshSurface\", \"PixelSurface\", \"Perimeter\", and \"MaximumDiameter\"** appear to be continuous quantitative measures.\n* The variables **\"PerimeterSurfaceRatio\", \"Sphericity\", \"SphericalDisproportion\", \"Elongation\", \"Autocorrelation\", \"ClusterProminence\", \"ClusterShade\", \"ClusterTendency\", \"Contrast\", \"Correlation\", \"DifferenceAverage\", \"DifferenceEntropy\", \"DifferenceVariance\", \"Idm\", \"Idmn\", \"Idn\", \"Imc1\", \"Imc2\", \"InverseVariance\", \"JointAverage\", \"JointEnergy\", \"JointEntropy\", \"MCC\", \"MaximumProbability\", \"SumAverage\", \"SumEntropy\", \"SumSquares\", \"Energy\", \"Entropy\", \"InterquartileRange\", \"Kurtosis\", \"MeanAbsoluteDeviation\", \"Median\", \"Range\", \"RobustMeanAbsoluteDeviation\", \"RootMeanSquared\", \"Skewness\", \"TotalEnergy\", \"Uniformity\", \"Variance\"** appear to be texture measures or features extracted from images.\n* The variable **\"MGMT_value\"** has a mean of 0.524786 and a standard deviation of 0.499813, indicating a bimodal distribution with slight positive skewness.\n* The surface variables **\"MeshSurface\" and \"PixelSurface\"** appear to have a considerable range, with values ranging from 336.5 to 6565.\n* The variable **\"Perimeter\"** has a mean of 450.439610 and a standard deviation (std) of 360.639463, indicating a relatively high dispersion of values. A relatively high spread of values means that object boundaries vary. The individual values can be far from the mean, which induces a great variability in the sizes and shapes of the objects present in the images.\n* The shape variables **\"Sphericity\", \"SphericalDisproportion\", \"Elongation\"** have mean values around 0.4 to 0.6, indicating a generally non-spherical shape of the depicted objects. (Brain)\n* The variable **\"Mean\"** has a mean of 879.400708 and a standard deviation of 1101.421810, indicating a relatively high variability in the mean values of the images. This suggests that the images show great diversity in their average values, resulting from different characteristics of the objects and the capture conditions.\n* The variable **\"Minimum\"** has a minimum value of 0, suggesting the possible presence of outliers or black pixels in the images. (See in previous Summary, [00109, 00123, 00709])","metadata":{"_uuid":"6c1fc1ea-c272-4095-adc9-ada2c7a5c99c","_cell_guid":"bbbd5753-0ffc-4646-a659-f8ab05319458","trusted":true}},{"cell_type":"markdown","source":"----","metadata":{"_uuid":"6dd73dd8-fbb0-4f7f-98dc-fd6c9b8903d7","_cell_guid":"57c4917a-ed53-434b-9a7e-5555d313b788","trusted":true}},{"cell_type":"markdown","source":"# TODO Yannick","metadata":{"_uuid":"122718d8-eda9-4901-bfab-b6c446dbc1f6","_cell_guid":"934bfbcc-04ad-4d18-ae1d-33f49676e95a","trusted":true}},{"cell_type":"markdown","source":"# First patient","metadata":{"_uuid":"71681f5a-3932-4b52-93f7-7ca168946d11","_cell_guid":"fa65f065-1fc3-4c94-8644-316618c77030","trusted":true}},{"cell_type":"code","source":"premiere_ligne = dataset.iloc[:1]\n\n# Convertir la première ligne en dictionnaire\npremiere_ligne_dict = premiere_ligne.to_dict(orient=\"records\")[0]\n\n# Formater l'affichage des colonnes et valeurs\naffichage_formate = \"\\n\".join([f\"{colonne}: {valeur}\" for colonne, valeur in premiere_ligne_dict.items()])\n\n# Afficher toutes les colonnes et valeurs\nprint(affichage_formate)","metadata":{"_uuid":"aec8067b-a7cf-4983-b65d-3d242fa107f8","_cell_guid":"2b12456b-b5e6-4e20-9ee2-f77f7fbff39e","execution":{"iopub.status.busy":"2023-05-21T18:25:38.593252Z","iopub.execute_input":"2023-05-21T18:25:38.593722Z","iopub.status.idle":"2023-05-21T18:25:38.607994Z","shell.execute_reply.started":"2023-05-21T18:25:38.593675Z","shell.execute_reply":"2023-05-21T18:25:38.606547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ℹ️\n- ID et BraTS21ID sont de même","metadata":{"_uuid":"bab957d0-76db-4a37-a3d6-8afe48d420c4","_cell_guid":"dafec231-cc39-46c0-9255-9db679a409b6","trusted":true}},{"cell_type":"code","source":"#init_dataset_radiomics()\n#img_resized = get_processed_image(0)\n#segmentation = segmentation_process(img_resized)\n#show_segmentation(img_resized,segmentation)\n#add_patient_data(0,img_resized,segmentation)\n#print(df_shapes.head()) \n#print(df_textures.head())\n#print(df_first_orders_features.head())\n\n# todo add targe into dateset","metadata":{"_uuid":"c961e747-b0d1-42f7-bf9c-5ab042e41e4f","_cell_guid":"0dc22bb8-61ad-4b72-bf88-bb8ca04d74e4","execution":{"iopub.status.busy":"2023-05-21T18:25:38.60915Z","iopub.execute_input":"2023-05-21T18:25:38.609486Z","iopub.status.idle":"2023-05-21T18:25:38.624001Z","shell.execute_reply.started":"2023-05-21T18:25:38.609458Z","shell.execute_reply":"2023-05-21T18:25:38.62299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"----","metadata":{"_uuid":"b02172b8-9fac-4a12-8122-57ef70a63404","_cell_guid":"ecb8ebad-b11b-49c3-bf57-9c4b03882abe","trusted":true}},{"cell_type":"markdown","source":"\n# Analysis","metadata":{"_uuid":"7ee67364-e4d3-4cbb-8ac9-1f9ddb49e2de","_cell_guid":"923a9c85-fc4d-45d4-afbc-baa6e61393d1","trusted":true}},{"cell_type":"markdown","source":"# Table TODO","metadata":{}},{"cell_type":"markdown","source":"> ","metadata":{}},{"cell_type":"markdown","source":"### Correlation Matrix","metadata":{}},{"cell_type":"code","source":"correlation_matrix = dataset.corr()\n\nfig, ax = plt.subplots(figsize=(50, 50))\nsns.heatmap(correlation_matrix, ax=ax, annot=True, cmap=\"coolwarm\")\nplt.title(\"Correlation Matrix\")\nplt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-21T18:25:38.625225Z","iopub.execute_input":"2023-05-21T18:25:38.626839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Correlation Matrix with Strong correlation\n\nAs a rule of correlation threshold:\n* 0.00-0.19: very weak.\n* 0.20-0.39: weak.\n* 0.40-0.59: moderate.\n* 0.60-0.79: strong.\n* 0.80-1.00: very strong.\n\nWe will use 0.7, strong.","metadata":{}},{"cell_type":"code","source":"correlation_threshold = 0.7\n# Filtrer by correlation threshold\nfiltered_correlation_matrix = filter_correlation_matrix(correlation_matrix, correlation_threshold)\n\nfig, ax = plt.subplots(figsize=(50, 50))\nsns.heatmap(filtered_correlation_matrix, ax=ax, annot=True, cmap=\"coolwarm\")\nplt.title(\"Correlation Matrix\")\nplt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-21T18:25:47.533255Z","iopub.execute_input":"2023-05-21T18:25:47.53432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Correlation group with threshold strength\n\nFor correlation threshold equal to **0.7, strong.**","metadata":{}},{"cell_type":"code","source":"correlation_threshold = 0.7\ngroups_correlated_threshold_07 = find_highly_correlated_groups(correlation_matrix, correlation_threshold)\n\nfor group_correlated in groups_correlated_threshold_07:\n    if len(group_correlated) > 1:\n        print(group_correlated)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For correlation threshold equal to **0.99, very strong.**","metadata":{}},{"cell_type":"code","source":"correlation_threshold = 0.99\ngroups_correlated_threshold_099 = find_highly_correlated_groups(correlation_matrix, correlation_threshold)\n\nfor group_correlated in groups_correlated_threshold_099:\n    if len(group_correlated) > 1:\n        print(group_correlated)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Analyse univariée\n\nTest de normalité utilisé : Shapiro-Wilk : Puissant et précis, recommandé pour les échantillons de petite taille\n\nTeste le skewness : mesure l'assymétrie d'une série (0 si suit loi normale). Lorsque la Skewness est égal à 0, le dataset est symétrique. Mais cette mesure nous renseigne aussi sur le type d’asymétrie.\n\nTeste le kurtosis : mesure l'applatissement (vaut 3 si loi normale de Laplace) mais on utilise aussi l'excédent de Kurtosis. Si le Kurtosis est supérieur à 3, alors l’ensemble de données est leptokurtique, c’est-à-dire que les queues sont plus épaisses que la normale. Cela indique un regroupement d’outliers.\n\nSi le Kurtosis est inférieur à 3, alors l’ensemble de données est platykurtique, c’est-à-dire que les queues sont plus fines que la normale. Cela indique un excès négatif d’outlier. En d’autres termes, la plupart des données ont tendance à se rassembler autour de la moyenne.\n\nLorsque le Kurtosis est égal à 3, alors l’ensemble de données est mésokurtique, c’est-à-dire que les queues sont les mêmes que dans une distribution normale.\n\nGraphiques utilisés :\n\n    histogramme avec courbe de densité de probabilité (le point rouge indique la moyenne)\n    boxplot\n    QQ plot (diagramme Quantile-Quantile) : permet d'évaluer la pertinence de l'ajustement d'une distribution donnée à un modèle théorique.","metadata":{"_uuid":"678aadc0-8814-4354-8ec9-c2a8759192ea","_cell_guid":"1ca84502-feef-49d2-ac16-d2dbf61f904f","trusted":true}},{"cell_type":"markdown","source":"<h3>Dataset complet</h3>","metadata":{"_uuid":"9b9c407c-e66c-497c-bfc8-be58734c6795","_cell_guid":"e1bdd8b2-3a7b-4145-be41-0c38ffb39def","trusted":true}},{"cell_type":"code","source":"describe=fonc_test_normality(dataset.drop('MGMT_value',axis=1))\n\nprint(\"Description dataset complet\")\ndescribe","metadata":{"_uuid":"f9a987c9-a99b-483a-ba13-91ce0b47dbec","_cell_guid":"6d24ff1f-a223-4ab0-95cb-064416bc914d","execution":{"iopub.status.busy":"2023-05-21T18:27:45.501825Z","iopub.execute_input":"2023-05-21T18:27:45.502148Z","iopub.status.idle":"2023-05-21T18:28:22.606968Z","shell.execute_reply.started":"2023-05-21T18:27:45.50212Z","shell.execute_reply":"2023-05-21T18:28:22.605772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3>Analyse sur l'ensemble du dataset, remarques :</h3>\n\nLe jeu de données montre que les les valeurs cibles sont homogènes.\n\nAucune des variables ne répond au test de Shapiro-Wilk indiquant que les variables explicatives ne suivent pas une loi normale.\n\nVariables ayant un skewness correct : Sphericity, Elongation, Idn, Range,\n\nVariables ayant un bon kurtosis : MajorAxisLength, Elongation, DifferenceAverage, DifferenceEntropy, Idn, JointAverage, SumAverage, Mean,\n\nEn analysant les graphiques, variables semblant bonnes sur le Q-Q plot sans trop de valeurs extrêmes : Elongation, DifferenceAverage, DifferenceEntropy, JointEntropy, SumEntropy, Entropy, Maximum, Range\n\nMais cela ne signifie pas que le dataset soit mauvais, il permet de faire ressortir les variables avec des valeurs extrêmes.\n\nElongation, Idn et Range semblent être homogènes.","metadata":{"_uuid":"f881251a-7f48-491c-97ba-900df3cf9b3d","_cell_guid":"2ee5a9fe-e42e-4824-9cff-ace937568311","trusted":true}},{"cell_type":"markdown","source":"<h3>Mêmes calculs mais que pour les MGMT_value = 1</h3>","metadata":{"_uuid":"29a8cf9c-236a-45ee-8408-612775050c8e","_cell_guid":"01fecaff-9fde-48c6-8d6f-a4d419f6593f","trusted":true}},{"cell_type":"code","source":"describe_MGMT_1=fonc_test_normality(dataset[dataset.MGMT_value == 1].drop('MGMT_value',axis=1),graphic=False)","metadata":{"_uuid":"b21decaf-aa92-4537-9c3b-dc378a669f95","_cell_guid":"8ef55878-afd4-489a-b088-8afcbaca74d7","execution":{"iopub.status.busy":"2023-05-21T18:26:26.881753Z","iopub.execute_input":"2023-05-21T18:26:26.882878Z","iopub.status.idle":"2023-05-21T18:26:27.129269Z","shell.execute_reply.started":"2023-05-21T18:26:26.882842Z","shell.execute_reply":"2023-05-21T18:26:27.127998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Description du dataset pour MGMT_value = 1\")\ndescribe_MGMT_1","metadata":{"_uuid":"a5999205-7b3f-46b5-8b36-d8896015f614","_cell_guid":"8c4b4afb-8909-4f9f-81a6-dac34402359b","execution":{"iopub.status.busy":"2023-05-21T18:26:27.130812Z","iopub.execute_input":"2023-05-21T18:26:27.131277Z","iopub.status.idle":"2023-05-21T18:26:27.192801Z","shell.execute_reply.started":"2023-05-21T18:26:27.131244Z","shell.execute_reply":"2023-05-21T18:26:27.191722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3>Comparaison des kurtosis et skewness</h3>","metadata":{"_uuid":"7dde8541-5dbc-43b4-969e-9310e0f4b8d9","_cell_guid":"9aad16ec-39b0-42a2-8337-b73d3bdff143","trusted":true}},{"cell_type":"code","source":"print(\"complet\")\ndescribe.loc[['skewness','excess_kurtosis'],:]","metadata":{"_uuid":"69c7078c-dede-47f6-b6c4-d0ca0fb9ac8b","_cell_guid":"28578326-e1c5-4a30-b2a0-f95cb2be6b0e","execution":{"iopub.status.busy":"2023-05-21T18:26:27.200006Z","iopub.execute_input":"2023-05-21T18:26:27.200486Z","iopub.status.idle":"2023-05-21T18:26:27.246255Z","shell.execute_reply.started":"2023-05-21T18:26:27.200434Z","shell.execute_reply":"2023-05-21T18:26:27.244599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"MGMT = 1\")\ndescribe_MGMT_1.loc[['skewness','excess_kurtosis'],:]","metadata":{"_uuid":"40f94844-c530-4384-be6b-b14d6a1e53a6","_cell_guid":"2451d4a8-fe0c-4147-9578-8395390fbf72","execution":{"iopub.status.busy":"2023-05-21T18:26:27.255341Z","iopub.execute_input":"2023-05-21T18:26:27.25577Z","iopub.status.idle":"2023-05-21T18:26:27.305551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Certaines variables ont un meilleur skewness avec un MGMT à 1 que par rapport au dataset global et inversement, ces mêmes variables sont donc sensibles au marqueurs. De même le Kurtosis est sensible aussi. Suivant les variables, la corrélation est positive ou négative entre skewness et kurtosis.","metadata":{"_uuid":"fefc4773-faad-464c-a756-aeec5e71a90a","_cell_guid":"09e0ef68-df03-429e-8947-c8ec49818fd4","trusted":true}},{"cell_type":"code","source":"print(\"Par variable, variation avec MGMT_value=1 par rapport au dataset global\")\nfor col in describe.columns :\n    skew = (describe_MGMT_1.loc['skewness',col]*100/describe.loc['skewness',col])-100\n    kurt = (describe_MGMT_1.loc['excess_kurtosis',col]*100/describe.loc['excess_kurtosis',col])-100\n    print (f\"{col:<32} : skewness {skew:>8.2f}%, excess_kurtosis {kurt:>8.2f}%\")","metadata":{"_uuid":"57ab64b7-37fb-4f32-a394-b1b8c94bd1ca","_cell_guid":"82d94129-b14c-4960-b228-b772dc4afede","execution":{"iopub.status.busy":"2023-05-21T18:26:27.30671Z","iopub.execute_input":"2023-05-21T18:26:27.30705Z","iopub.status.idle":"2023-05-21T18:26:27.326738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Une première conclusion pourrait être qu'un gliocome dont la valeur du MGMT = 0 présenterait des variables contenant plus d'outliers.\n\nIl y a des exceptions avec des variation semblant abbérantes comme l'excess de kurtosis pour la variable MajorAxisLength qui explose avec une augmentation de presque 1232%.\n\nCes variations pourrait indiquer les variables ayant un impact plus important par rapport à la valeur cible. Par Exemple Sphericity à moins d'outliers avec MGMT_value à 1, une meilleur normalité d'Idn.","metadata":{"_uuid":"cc99ed85-fb08-478b-b1ce-2e1328c2ba18","_cell_guid":"d9b456e6-5689-4ae7-bd9c-cb79bdd4e52c","trusted":true}},{"cell_type":"code","source":"# Comparaison avec MGMT_value = 0\ndescribe_MGMT_0 = fonc_test_normality(dataset[dataset.MGMT_value == 0].drop('MGMT_value',axis=1),graphic=False)\nprint(\"Par variable, variation avec MGMT_value=0 par rapport au dataset global\")\nfor col in describe.columns :\n    skew = (describe_MGMT_0.loc['skewness',col]*100/describe.loc['skewness',col])-100\n    kurt = (describe_MGMT_0.loc['excess_kurtosis',col]*100/describe.loc['excess_kurtosis',col])-100\n    print (f\"{col:<32} : skewness {skew:>8.2f}%, excess_kurtosis {kurt:>8.2f}%\")","metadata":{"_uuid":"90f3e4e1-7c78-4878-ad52-d88c7ffa49db","_cell_guid":"c8870a61-7f20-461f-823b-5dbd8f23b61f","execution":{"iopub.status.busy":"2023-05-21T18:26:27.328627Z","iopub.execute_input":"2023-05-21T18:26:27.329088Z","iopub.status.idle":"2023-05-21T18:26:27.576797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3>Exemple : comparaison de Sphericity, Entropy, ClusterProminence\nafin de vérifier la normalité en fonction de la valeur cible","metadata":{"_uuid":"6caf4344-cf55-4313-bb09-7b8d2a265859","_cell_guid":"0f412cee-de76-4d05-8777-4201bd9e092e","trusted":true}},{"cell_type":"code","source":"print(\"Sphericity pour MGMT_value=1\")\nfonc_test_normality(dataset[dataset.MGMT_value == 1][['Sphericity']],graphic=True)      \n\nprint(\"Sphericity pour MGMT_value=0\")\nfonc_test_normality(dataset[dataset.MGMT_value == 0][['Sphericity']],graphic=True)   \n\nprint(\"Entropy pour MGMT_value=1\")\nfonc_test_normality(dataset[dataset.MGMT_value == 1][['Entropy']],graphic=True)      \n\nprint(\"Entropy pour MGMT_value=0\")\nfonc_test_normality(dataset[dataset.MGMT_value == 0][['Entropy']],graphic=True)  \n\nprint(\"ClusterProminence pour MGMT_value=1\")\nfonc_test_normality(dataset[dataset.MGMT_value == 1][['ClusterProminence']],graphic=True)      \n\nprint(\"ClusterProminence pour MGMT_value=0\")\nfonc_test_normality(dataset[dataset.MGMT_value == 0][['ClusterProminence']],graphic=True)","metadata":{"_uuid":"88802d28-a8a4-4c66-a868-00ad667549aa","_cell_guid":"d20d4331-54dd-48c8-a43f-2b6ea9619282","execution":{"iopub.status.busy":"2023-05-21T18:29:44.292105Z","iopub.execute_input":"2023-05-21T18:29:44.292673Z","iopub.status.idle":"2023-05-21T18:29:47.97693Z","shell.execute_reply.started":"2023-05-21T18:29:44.292628Z","shell.execute_reply":"2023-05-21T18:29:47.975605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3>Détection des outliers</h3>\nUtilisation du IQR (interquartile range)","metadata":{"_uuid":"f23b91a1-94e5-4af4-81da-23953ddfc1bf","_cell_guid":"c39d0464-b088-448d-bbd7-32806957d648","trusted":true}},{"cell_type":"code","source":"q1=dataset.quantile(0.25)\nq3=dataset.quantile(0.75)\n\nIQR=q3-q1\n\noutliers = dataset[((dataset<(q1-1.5*IQR)) | (dataset>(q3+1.5*IQR)))]\noutliers\n\noutliers_removed = outliers.dropna().reset_index()\nprint(outliers_removed)","metadata":{"_uuid":"c89acc0c-4e1c-4777-9e9c-3aa084094099","_cell_guid":"9323b456-3471-4f10-bfcd-36b58d0dbe7b","_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-05-21T18:26:31.760864Z","iopub.execute_input":"2023-05-21T18:26:31.76136Z","iopub.status.idle":"2023-05-21T18:26:31.78535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ----","metadata":{"_uuid":"838c46d1-5deb-49e2-b9fa-67f42d55a39b","_cell_guid":"93005cf6-77ab-4522-95ad-6fda807d9131","trusted":true}},{"cell_type":"code","source":"# TODO","metadata":{"_uuid":"b4c7cb58-b8fe-40bb-842d-16f434748538","_cell_guid":"9fe13027-424f-41f4-9545-38270032f811","execution":{"iopub.status.busy":"2023-05-21T18:26:31.786699Z","iopub.execute_input":"2023-05-21T18:26:31.787052Z","iopub.status.idle":"2023-05-21T18:26:31.792769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#TODO","metadata":{"_uuid":"73649b95-58f1-488e-acb9-b69546b3bffb","_cell_guid":"8c05f217-1eb9-40f6-8b57-db22348f3cc4","execution":{"iopub.status.busy":"2023-05-21T18:26:31.794465Z","iopub.execute_input":"2023-05-21T18:26:31.795204Z","iopub.status.idle":"2023-05-21T18:26:31.807122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#TODO","metadata":{"_uuid":"37409e90-f9d1-4d73-89b5-8d9cf92e56e3","_cell_guid":"79380149-a1f5-4bbe-a7d5-81ffe408f892","execution":{"iopub.status.busy":"2023-05-21T18:26:31.808403Z","iopub.execute_input":"2023-05-21T18:26:31.808784Z","iopub.status.idle":"2023-05-21T18:26:31.818468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#TODO","metadata":{"_uuid":"5a6289ec-4a69-4b76-9ed8-ebfc32a0632b","_cell_guid":"90495e54-e071-4a88-8891-fe6674293bc7","execution":{"iopub.status.busy":"2023-05-21T18:26:31.819491Z","iopub.execute_input":"2023-05-21T18:26:31.819863Z","iopub.status.idle":"2023-05-21T18:26:31.830174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#TODO","metadata":{"_uuid":"e8ba0c17-4443-427d-a973-10d0162db64d","_cell_guid":"2d18053e-3c34-41b4-8721-0b870038dc9d","execution":{"iopub.status.busy":"2023-05-21T18:26:31.831382Z","iopub.execute_input":"2023-05-21T18:26:31.8318Z","iopub.status.idle":"2023-05-21T18:26:31.84261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Etape 3/ Nettoyage et Pre-processing :","metadata":{"_uuid":"99318ba2-3318-4a45-8c01-2b39abac6d6c","_cell_guid":"28f3e9d5-0cea-4f4d-93ca-10e737c94d54","trusted":true}},{"cell_type":"code","source":"#TODO","metadata":{"_uuid":"090b97c3-b9bc-463f-9eb7-a693a651efd5","_cell_guid":"762d1f72-ec8b-488c-90e4-1cfb7ccad9e1","execution":{"iopub.status.busy":"2023-05-21T18:26:31.844204Z","iopub.execute_input":"2023-05-21T18:26:31.84459Z","iopub.status.idle":"2023-05-21T18:26:31.854547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#TODO","metadata":{"_uuid":"ebf4bba3-c67b-4c6d-a4f6-bddab5e36574","_cell_guid":"a70a131e-1889-4b37-b497-c22aa2845336","execution":{"iopub.status.busy":"2023-05-21T18:26:31.855987Z","iopub.execute_input":"2023-05-21T18:26:31.856311Z","iopub.status.idle":"2023-05-21T18:26:31.867892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#TODO","metadata":{"_uuid":"ee86f03e-70f8-4490-92a6-37ed75a5a28f","_cell_guid":"e471b34f-d7cd-4c53-86fb-f1d85dd9540d","execution":{"iopub.status.busy":"2023-05-21T18:26:31.869691Z","iopub.execute_input":"2023-05-21T18:26:31.87004Z","iopub.status.idle":"2023-05-21T18:26:31.88136Z"},"trusted":true},"execution_count":null,"outputs":[]}]}